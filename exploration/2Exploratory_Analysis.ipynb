{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to understand customer and seller interactions through Olist, we will perform an analysis of customer purchases over time. Our questions of interest will revolve around profit, products and reviews. We want to know what products produce the most income and are bought most frequently. We also want to know which are highest rated and if there is a seasonal correlation to customer satisfaction. Since our end goal is to create a recommendation system, understanding the product options and customer experience will help us know what features are most important for recommendations. \n",
    "\n",
    "The exploratory analysis below was performed using personalized graphing functions found in the functions folder and imported as \"graphing\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import plotly.offline\n",
    "import cufflinks as cf\n",
    "cf.go_offline()\n",
    "cf.set_config_file(offline=False, world_readable=True)\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "seller_dt_cols = ['shipping_limit_date', 'review_creation_date', 'review_answer_timestamp']\n",
    "customer_dt_cols = ['shipping_limit_date', 'review_creation_date', 'review_answer_timestamp', 'order_purchase_timestamp',\\\n",
    "                'order_delivered_customer_date', 'order_estimated_delivery_date']\n",
    "\n",
    "customers = pd.read_csv('modified_data/customers.csv', \n",
    "                        index_col=0, delimiter = ',', \n",
    "                        parse_dates = customer_dt_cols, \n",
    "                        infer_datetime_format = True, \n",
    "                        low_memory=False)\n",
    "sellers = pd.read_csv('modified_data/sellers.csv', \n",
    "                      index_col=0, delimiter = ',', \n",
    "                      parse_dates = seller_dt_cols, \n",
    "                      infer_datetime_format = True, \n",
    "                      low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which product type generated the most profit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_count(df, column, count):\n",
    "    \n",
    "    new_df = df.groupby(column).filter(lambda x: len(x) > count)\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_filtered_groupby(title, df, groupby_col, sort_col, min_count, agg_func = sum, count = False, size = (10, 8)):\n",
    "    \n",
    "    if count == False:\n",
    "        df_filtered = filter_by_count(df, groupby_col, min_count)\\\n",
    "                             [[groupby_col, sort_col]]\\\n",
    "\n",
    "        df_agg = df_filtered.groupby([groupby_col])[sort_col]\\\n",
    "                            .apply(agg_func)\\\n",
    "                            .reset_index()\\\n",
    "                            .sort_values([sort_col], ascending = False)\n",
    "    else:\n",
    "        df_filtered = filter_by_count(df, groupby_col, min_count)\\\n",
    "                                    [groupby_col].reset_index()\n",
    "    \n",
    "        df_agg = df_filtered.groupby([groupby_col])\\\n",
    "                                          .count()\\\n",
    "                                          .sort_values([sort_col], ascending = False)\\\n",
    "                                          .reset_index()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=size)\n",
    "    ax.set_title(title, fontsize=16)\n",
    "    ax = sns.barplot(data=df_agg, x=sort_col, y=groupby_col, color = 'cyan')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# group by the category column and limit the products to the ones that were bought at least 500 times\n",
    "plot_filtered_groupby(\"Total Profit per item\", customers, 'product_category_name', 'price', 500, sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> It looks like heath and beauty, watches, bed and bath, sports leisure and computer accessories round out the top 5 most profittable product categories. There are 11 items that grossed more than 400k over the approximately 2 year time span the data covers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which products are purchased most frequently?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_filtered_groupby(\"Most Popular by total items purchased\", customers, 'product_category_name', 'index', 500, count = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The most frequently bought items generally correlate well with the highest grossing products. Watches and gifts fall out of the top 5 which implies the items on average must be relatively high. Sports leasure is the third highest purchased item but is not in the top 5 highest grossing items, implying that average cost may be lower relative to the majority. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which product has the highest average cost for the customer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_filtered_groupby(\"Average Cost per Category\", customers, 'product_category_name', 'price', 500, np.mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Not suprizingly we see that watches and gifts are in the top 5 most costly items, with sports and leisure items falling out of the top 15 most costly items, confirming former assumptions. Musical Instruments, small appliances and watches and gifts are the most costly categories. One interesting finding is that watches and gifts and auto products are the only two groups that fit into the top 10 for cost, profit and most frequently bought.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the highest rated products?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_filtered_groupby(\"Average Rating out of 5\", customers, 'product_category_name', 'review_score', 500, np.mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> It looks like many of the highest grossing products fall on the lower end of the average review score with the exception of health and beauty, and sports leisure. Small appliances is highly rated and has a high average cost, but this is a category that falls on the lower end for gross profit and number of times purchased. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Seasonal Trends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this analysis we will switch to a yearly view starting from July of 2017 to July of 2018. Olist during 2017 was still growing, making themselves much more widely known on black friday of 2017. The growth in sales during the period noted will give a better picture of yearly trends for their growth after this point. For each of the plots below the aggregations are made using the day and time the item was purchased, as opposed to when it was delivered or noted in the system. This will give us a better perspective of the customer and for us to note any seasonal purchase trends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When is Olist receiving the most profit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeseries_plot(title, df, timeseries_col, y_col, dStart, dEnd, agg_func = sum, count = False, sample_by = 'D', axvline=[np.nan], size = (12, 6)):\n",
    "    \n",
    "    if count == True:\n",
    "        timeseries_vs_y = df[[timeseries_col, y_col]]\n",
    "        plot_df = timeseries_vs_y.set_index(timeseries_col).resample(sample_by)[y_col].count()\n",
    "        df = plot_df[(dStart <= plot_df.index) & (plot_df.index <= dEnd)]\n",
    "    \n",
    "    else:\n",
    "        timeseries_vs_y = df[[timeseries_col, y_col]]\n",
    "        plot_df = timeseries_vs_y.set_index(timeseries_col).resample(sample_by)[y_col].apply(agg_func)\n",
    "        df = plot_df[(dStart <= plot_df.index) & (plot_df.index <= dEnd)]\n",
    "\n",
    "    ax = plt.figure(figsize=size).add_subplot(111)   \n",
    "    xticks = pd.date_range(start=dStart, end=dEnd, freq='M')\n",
    "\n",
    "    df.plot(ax = ax, xticks = xticks)\n",
    "    \n",
    "    for axv in axvline:\n",
    "        ax.axvline(axv, color='r', linestyle='--', lw=1)\n",
    "    \n",
    "    ax.set_title(title, fontsize=16)\n",
    "    ax.set_xticklabels([x.strftime('%h%d\\n%Y') for x in xticks])\n",
    "    plt.setp(ax.xaxis.get_majorticklabels(), ha='right')\n",
    " \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dStart = datetime.datetime(2017,7,1) # 1 July 2017\n",
    "dEnd = datetime.datetime(2018,7,1) # 1 July 2018\n",
    "vline = [datetime.datetime(2017, 11,24), # 24th Novem \"Black Friday\"\n",
    "         datetime.datetime(2018, 5,10), # 10th May 2018\n",
    "         datetime.datetime(2018, 6,11), # 11th June 2018\n",
    "         datetime.datetime(2018, 2,28)] # 28th Feb 2018\n",
    "timeseries_plot('Total Profit, Summed by Week', \n",
    "                customers, \n",
    "                'order_purchase_timestamp', \n",
    "                'price',  \n",
    "                dStart, \n",
    "                dEnd,\n",
    "                sum,\n",
    "                sample_by='W', \n",
    "                axvline = vline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> There is a clear uptick for one day in 2017, this corresponded to \"Black Friday\" around the world and clearly was the cause of this jump in sales. There follows a drop with another uptick in early January. Sales seem to steadily increase from this point through to the summer months, where there is a peak in early May and mid June."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many products were they selling per week over the same period?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vline = [datetime.datetime(2017, 11,24), # 24th Novem \"Black Friday\"\n",
    "         datetime.datetime(2018, 5,10), # 10th May 2018\n",
    "         datetime.datetime(2018, 6,11), # 11th June 2018\n",
    "         datetime.datetime(2018, 2,28)] # 28th Feb 2018\n",
    "timeseries_plot('Total Items Sold per Week', \n",
    "                customers, \n",
    "                'order_purchase_timestamp', \n",
    "                'product_count',\n",
    "                dStart, \n",
    "                dEnd,\n",
    "                count=True,\n",
    "                sample_by='W', \n",
    "                axvline = vline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> What we can see is that after the black friday surge experienced on February 28th, there was a sharp drop in purchases but it is clear that they were able to aquire a larger customer base who returned to the website for more purchases beginning in early January."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do review scores change over time? Are there any seasonal trends?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Vertical lines marking dips in review\n",
    "vline = [datetime.datetime(2017, 11, 24), # Corresponds with Black Friday\n",
    "         datetime.datetime(2018, 2, 28), # corresponds with peak above 28th Feb 2018\n",
    "         datetime.datetime(2018, 5, 14), # Drop in review score on 14th May, not corresponding to profit\n",
    "         datetime.datetime(2018, 6,11) # Drop in review score on 5th June, not corresponding to profit\n",
    "        ]\n",
    "timeseries_plot('Average Product Review Score', \n",
    "                customers, \n",
    "                'order_purchase_timestamp', \n",
    "                'review_score',  \n",
    "                dStart, \n",
    "                dEnd,\n",
    "                np.mean,\n",
    "                sample_by='W', \n",
    "                axvline = vline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The average review score drops during high volume purchasing periods. The vertical lines noted above correspond to the high volume period noted in the previous plot. There are two discrepencies however, on February 28th there is a minor increase in sales but this corresponds to an extremely large drop in review scores. Also, as can be seen in the plot above, the increase in sales in mid June does not correlate to the drop seen above earlier in the month. There may be some outlier cause here, or a seasonal challenge with delivery times that affects reviews that needs to be investigated further. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### During what seasons are late delivery times the most significant? How does this affect customer satisfaction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#customers[customers['order_delivered_customer_date'] > customers['order_estimated_delivery_date']].count()\n",
    "customers['on_time'] = (customers['order_estimated_delivery_date']\n",
    "                           >=\n",
    "                        customers['order_delivered_customer_date'])\n",
    "\n",
    "customers['diff_days'] = (customers['order_delivered_customer_date']\n",
    "                             -\n",
    "                          customers['order_estimated_delivery_date'])\n",
    "\n",
    "customers['diff_days'] = customers['diff_days']/np.timedelta64(1, 'D')\n",
    "customers['satisfied'] = (customers['review_score'] >= 3)\n",
    "# Create product_count column for the rating\n",
    "\n",
    "customers['product_count'] = customers['product_id']\\\n",
    "                                                    .groupby(customers['customer_unique_id'])\\\n",
    "                                                    .transform('count')\n",
    "\n",
    "delivery_time = customers[['order_delivered_customer_date', 'order_estimated_delivery_date', \n",
    "                           'review_score', 'order_purchase_timestamp', 'satisfied', 'diff_days', \n",
    "                           'on_time', 'product_count', 'product_id', 'product_category_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate only the late deliveries\n",
    "late_deliveries = delivery_time.loc[delivery_time['on_time'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vline = [datetime.datetime(2017, 11,24), # 24th Novem \"Black Friday\"\n",
    "         datetime.datetime(2018, 5,14), # 10th May 2018\n",
    "         datetime.datetime(2018, 6,11), # 11th June 2018\n",
    "         datetime.datetime(2018, 2,28)] # 28th Feb 2018\n",
    "timeseries_plot('Total Number of Late Deliveries', \n",
    "                late_deliveries, \n",
    "                'order_purchase_timestamp', \n",
    "                'product_count',\n",
    "                dStart, \n",
    "                dEnd,\n",
    "                count=True,\n",
    "                sample_by='W',\n",
    "                axvline=vline, \n",
    "               size=(15,5))\n",
    "\n",
    "timeseries_plot('Portion of Customers Considered Satisfied over Time', \n",
    "                delivery_time, \n",
    "                'order_purchase_timestamp', \n",
    "                'satisfied',\n",
    "                dStart, \n",
    "                dEnd,\n",
    "                np.mean,\n",
    "                sample_by='W',\n",
    "                axvline=vline, \n",
    "               size=(15,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> There is clearly a relationship between customer satisfaction and on-time delivery. The number of satisfied customers dip dramatically for the three main high volume periods. There is one dip on June 6th that is not accounted for however. This corresponds to the same dip seen in product review score, which is to be expected. This may be a date to investigate to see what kinds of products were bought and why customers may have been dissatisfied. \n",
    "\n",
    "> It is also clear now what is causing the dip in average product review scores identified previously on February 28th. Although this day had no where near the volume of orders seen on black friday, it had almost as many late deliveries on products ordered on this day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigating June 6th drop in customer satisfaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns of interest\n",
    "columns = ['order_purchase_timestamp', 'product_id', 'product_category_name', \n",
    "                'satisfied', 'review_score', 'diff_days', 'on_time']\n",
    "# set min and max to encompass the entire day of june 4th\n",
    "june_sixth = customers[(customers.order_purchase_timestamp >= datetime.datetime(2018, 6, 6)) \\\n",
    "                          & (customers.order_purchase_timestamp <= datetime.datetime(2018, 6, 7))]\\\n",
    "                            [columns]\n",
    "feb_twentyeight = late_deliveries[(late_deliveries.order_purchase_timestamp >= datetime.datetime(2018, 2, 28)) \\\n",
    "                          & (late_deliveries.order_purchase_timestamp <= datetime.datetime(2018, 3, 1))]\\\n",
    "                            [columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_filtered_groupby(\"June 6th Purchases\", june_sixth, 'product_category_name', 'index', 0, count = True, size = (10, 6))\n",
    "plot_filtered_groupby(\"June 6th Ratings\", june_sixth, 'product_category_name', 'review_score', 0, np.mean, size = (10, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Suprizingly there were only 3 late items on June 6th, two of which were rated as unsatisfactory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_filtered_groupby(\"February 28th Late Deliveries\", feb_twentyeight, 'product_category_name', 'index', 0, count = True, size = (10, 5))\n",
    "plot_filtered_groupby(\"Febrary 28th Late Ratings\", feb_twentyeight, 'product_category_name', 'review_score', 0, np.mean, size = (10, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Many more items were delivered late on February 28th, many of which were rated at or below a 3, our satisfactory benchmark. Notebly, sports leasure and computer accessories made up most of the late deliveries but averaged below a 3 rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "total = june_sixth.satisfied.count()\n",
    "pct = np.mean(june_sixth.satisfied)\n",
    "late_pct = np.mean(june_sixth.on_time)\n",
    "print(\"Total number of purchases on June sixth: \")\n",
    "print(total, \"\\n\")\n",
    "print(\"Percent of satisfied customers: \\n{:.1f}%\\n\".format(pct*100))\n",
    "print(\"Percent of on-time deliveries: \\n{:.1f}%\".format(late_pct*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "total = feb_twentyeight.satisfied.count()\n",
    "pct = np.mean(feb_twentyeight.satisfied)\n",
    "late_pct = np.mean(feb_twentyeight.on_time)\n",
    "print(\"Total number of purchases on Feb 28th for comparison: \")\n",
    "print(total, \"\\n\")\n",
    "print(\"Percent of satisfied customers: \\n{:.1f}%\\n\".format(pct*100))\n",
    "print(\"Percent of on-time deliveries: \\n{:.1f}%\".format(late_pct*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> It appears that bed bath tables and housewares are the primary reason for a dip in reviews on June 4th in 2018. They were the top two items bought that day but were the among the worst rated. What should also be noted is that the percentage of on time deliveries was not correlated to the drop in reviews like many other instances. Almost all of the deliveries were on time, as compared to February 28th when less that 75% of packages were delivered on time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary from Exploratory Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory analysis revealed a number of interesting factors contributing to customer satisfaction. The strongest predictor was delivery time. We also found that many of the most popular categories were also some of the worst rated. While this could simply be because of the fact that the items were purchased more, leading to more chances for lower ratings to appear, there could be more contributing to lower ratings. After investigating a case study on June 6th, it was found that the same categories with lower ratings were recieving lower scores although the items were delivered on time. \n",
    "\n",
    "While customer satisfaction will not directly contribute our recommendation system, it does give us a sense of what Olist offers and what customers are buying most. The most popular categories were found to be bed bath, furniture decorations, sports leisure and computer accessories. These items will be some of the primary linkages between customers and how we recommend items. Another factor to be noted are the number of products that were not purchased at least 500 times within a year span. While there are 72 categories, only 27 were popular over that time frame. \n",
    "\n",
    "The challenges we face in creating our recommendation system will be with recommending items that may fit a customers purchasing habits but were not bought enough by others to be considered. To combat this our approach will rely on a hybrid approach, which takes into consideration not only what other customers bought, but also information about the user and the products they purchased. This will help combat a common problem for recommendation systems, which is the \"cold start\" issue that arises with new customers. For our purposes it will also help with the number of customers who purchased from Olist only once."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
